import glob
import gzip
import io
import pandas as pd
import tempfile

from typing import Literal, Optional
from typing_extensions import Self

from ..data import SQLAdapter


class PostgreSQL(SQLAdapter):

    driver = 'postgresql+psycopg2'
    default_port = 5432
    quote = '"'
    data_types = {
        'varchar': 'VARCHAR',
        'text': 'TEXT',
        'date': 'DATE',
        'datetime': 'TIMESTAMP',
        'numeric': 'DECIMAL',
        'tinyint': 'SMALLINT',
        'smallint': 'SMALLINT',
        'mediumint': 'INTEGER',
        'integer': 'INTEGER',
        'bigint': 'BIGINT',
        'boolean': 'BOOLEAN'
    }
    autokey_suffix = 'GENERATED BY DEFAULT AS IDENTITY'
    
    def execute_load(
        self,
        query: str,
        path: Optional[str] = None
    ) -> Self:
        self.connect()

        connection = self._client.raw_connection()
        cursor = connection.cursor()

        bpath = '{}/{}*'.format(self.app.fspath, path)
        files = sorted(glob.glob(bpath))

        try:
            for path in files:
                with open(path, 'rb') as fh:
                    if path[-3:] == '.gz':
                        with gzip.GzipFile(mode='rb', fileobj=fh) as gz:
                            buffer = io.BytesIO(gz.read())
                    else:
                        buffer = io.BytesIO(fh.read())

                    buffer.seek(0)
                    cursor.copy_expert(query, buffer)

            connection.commit()
        except Exception as e:
            connection.rollback()
            raise e
        finally:
            cursor.close()
            connection.close()
            self.disconnect()

        return self

    def execute_unload(
        self,
        query: str,
        path: Optional[str] = None
    ) -> Self:
        self.connect()

        connection = self._client.raw_connection()
        cursor = connection.cursor()

        path = '{}/{}'.format(self.app.fspath, path)

        try:
            if path is not None:
                with open(path, 'wb') as fh:
                    cursor.copy_expert(query, fh)

                result = 1
            else:
                with tempfile.TemporaryFile() as tf:
                    cursor.copy_expert(query, tf)

                    tf.seek(0)
                    result = pd.read_csv(tf)
        except Exception as e:
            connection.rollback()
            raise e
        finally:
            cursor.close()
            connection.close()
            if not self.in_session():
                self.disconnect()

        return result

    def build_load_query(
        self,
        table: str,
        header: bool = False,
        fmt: Optional[str] = 'csv',
        sep: Optional[str] = ',',
        stage: Optional[str] = None,
        compression: Optional[Literal['gzip']] = None,
        **kwargs
    ) -> tuple[str, str]:
        if stage is None:
            stage = self.get_table_name(table)

        path = '{}/{}/{}'.format(self.stage_dir, stage, stage)

        cmd = [
            'FORMAT {fmt}',
            "DELIMITER '{sep}'",
            "NULL ''"
        ]

        if header:
            cmd.append('HEADER')
        
        if int(self.get_version().split('.')[0]) >= 16:
            cmd.append("DEFAULT 'DEFAULT'")

        query = 'COPY {table} FROM STDIN WITH ({cmd})'.format(
            table=table,
            cmd=', '.join(cmd).format(
                fmt=fmt,
                sep=sep
            )
        )

        return query, path

    def build_unload_query(
        self,
        table: str,
        query: str,
        header: bool = False,
        fmt: Optional[str] = 'csv',
        sep: Optional[str] = ',',
        stage: Optional[str] = None,
        compression: Optional[Literal['gzip']] = None,
        **kwargs
    ) -> tuple[str, str]:
        if stage is None:
            stage = self.get_table_name(table)

        path = '{}/{}/{}.{}'.format(self.stage_dir, stage, stage, fmt)
        if compression == 'gzip':
            path += '.gz'

        cmd = [
            'FORMAT {fmt}',
            "DELIMITER '{sep}'",
            "NULL ''"
        ]

        if header:
            cmd.append('HEADER')

        query = "COPY ('{query}') TO STDOUT WITH ({cmd})".format(
            query=query,
            cmd=', '.join(cmd).format(
                fmt=fmt,
                sep=sep
            )
        )

        return query, path
    
    def get_version(
        self
    ) -> str:
        return self.get_var(query='SHOW server_version')
    
    def get_tables(
        self,
        schema: Optional[str] = None
    ) -> list[str]:
        query = "SELECT table_name FROM information_schema.tables WHERE table_schema = '{}'".format(schema or 'public')
        
        tables = self.get_results(query=query)['table_name'].tolist()

        return tables
    
    def get_columns(
        self,
        table: str
    ) -> list[str]:
        schema, name = self.get_table_parts(table)
        
        query = "SELECT column_name FROM information_schema.columns WHERE table_name = '{}'".format(name)
        if schema is not None:
            query += " AND table_schema = '{}'".format(schema)
        
        columns = self.get_results(query=query)['column_name'].tolist()

        return columns
    
    def get_meta(
        self,
        table: str
    ) -> dict[str, dict]:
        meta = {
            col: {} for col in self.get_columns(table)
        }

        return meta

    def reset_autokey(
        self,
        table: str,
        key: str
    ) -> Self:
        self.execute(
            "SELECT SETVAL('{table}_{key}_seq', COALESCE(MAX({key}), 1)) FROM {table}".format(
                table=table,
                key=key
            ),
            autocommit=True
        )

        return self

    def vacuum(
        self,
        table: str
    ) -> Self:
        self.execute(
            'VACUUM (FULL, ANALYZE) {}'.format(table),
            autocommit=True
        )

        return self
